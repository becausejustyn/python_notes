{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  6.]\n",
      " [ 6. 12. 18.]\n",
      " [10. 20. 30.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-31 13:15:30.127738: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "x = tf.compat.v1.placeholder(tf.float32, name = \"x\")\n",
    "# x = [[2., 4., 6.]]\n",
    "y = tf.compat.v1.placeholder(tf.float32, name = \"y\")\n",
    "# y = [[1.], [3.], [5.]]\n",
    "\n",
    "multiply = tf.multiply(x, y)\n",
    "\n",
    "with tf.compat.v1.Session() as session:\n",
    "    m = session.run(\n",
    "        multiply, feed_dict={x: [[2., 4., 6.]], y: [[1.], [3.], [5.]]}\n",
    "    )\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_1:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[2., 4., 6.]]\n",
    "y = [[1.], [3.], [5.]]\n",
    "m = tf.multiply(x, y)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  6.],\n",
       "       [ 6., 12., 18.],\n",
       "       [10., 20., 30.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[2., 4., 6.]])\n",
    "y = np.array([[1.], [3.], [5.]])\n",
    "\n",
    "m = torch.mul(torch.from_numpy(x), torch.from_numpy(y))\n",
    "\n",
    "m.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is: 2.1672\n"
     ]
    }
   ],
   "source": [
    "input_vector = [1.72, 1.23]\n",
    "weights_1 = [1.26, 0]\n",
    "weights_2 = [2.17, 0.32]\n",
    "\n",
    "# Computing the dot product of input_vector and weights_1\n",
    "first_indexes_mult = input_vector[0] * weights_1[0]\n",
    "second_indexes_mult = input_vector[1] * weights_1[1]\n",
    "dot_product_1 = first_indexes_mult + second_indexes_mult\n",
    "\n",
    "print(f\"The dot product is: {dot_product_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is: 2.1672\n"
     ]
    }
   ],
   "source": [
    "dot_product_1 = np.dot(input_vector, weights_1)\n",
    "\n",
    "print(f\"The dot product is: {dot_product_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is: 4.1259999999999994\n"
     ]
    }
   ],
   "source": [
    "dot_product_2 = np.dot(input_vector, weights_2)\n",
    "\n",
    "print(f\"The dot product is: {dot_product_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result is: [0.7985731]\n"
     ]
    }
   ],
   "source": [
    "# Wrapping the vectors in NumPy arrays\n",
    "input_vector = np.array([1.66, 1.56])\n",
    "weights_1 = np.array([1.45, -0.66])\n",
    "bias = np.array([0.0])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def make_prediction(input_vector, weights, bias):\n",
    "     layer_1 = np.dot(input_vector, weights) + bias\n",
    "     layer_2 = sigmoid(layer_1)\n",
    "     return layer_2\n",
    "\n",
    "prediction = make_prediction(input_vector, weights_1, bias)\n",
    "\n",
    "print(f\"The prediction result is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result is: [0.87101915]\n"
     ]
    }
   ],
   "source": [
    "# Changing the value of input_vector\n",
    "input_vector = np.array([2, 1.5])\n",
    "\n",
    "prediction = make_prediction(input_vector, weights_1, bias)\n",
    "\n",
    "print(f\"The prediction result is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0\n",
    "\n",
    "mse = np.square(prediction - target)\n",
    "\n",
    "print(f\"Prediction: {prediction}; Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative = 2 * (prediction - target)\n",
    "\n",
    "print(f\"The derivative is {derivative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the weights\n",
    "weights_1 = weights_1 - derivative\n",
    "\n",
    "prediction = make_prediction(input_vector, weights_1, bias)\n",
    "\n",
    "error = (prediction - target) ** 2\n",
    "\n",
    "print(f\"Prediction: {prediction}; Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "derror_dprediction = 2 * (prediction - target)\n",
    "layer_1 = np.dot(input_vector, weights_1) + bias\n",
    "dprediction_dlayer1 = sigmoid_deriv(layer_1)\n",
    "dlayer1_dbias = 1\n",
    "\n",
    "derror_dbias = (\n",
    "    derror_dprediction * dprediction_dlayer1 * dlayer1_dbias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.weights = np.array([np.random.randn(), np.random.randn()])\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_deriv(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "        return prediction\n",
    "\n",
    "    def _compute_gradients(self, input_vector, target):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "\n",
    "        derror_dprediction = 2 * (prediction - target)\n",
    "        dprediction_dlayer1 = self._sigmoid_deriv(layer_1)\n",
    "        dlayer1_dbias = 1\n",
    "        dlayer1_dweights = (0 * self.weights) + (1 * input_vector)\n",
    "\n",
    "        derror_dbias = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dbias\n",
    "        )\n",
    "        derror_dweights = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dweights\n",
    "        )\n",
    "\n",
    "        return derror_dbias, derror_dweights\n",
    "\n",
    "    def _update_parameters(self, derror_dbias, derror_dweights):\n",
    "        self.bias = self.bias - (derror_dbias * self.learning_rate)\n",
    "        self.weights = self.weights - (\n",
    "            derror_dweights * self.learning_rate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "neural_network = NeuralNetwork(learning_rate)\n",
    "\n",
    "neural_network.predict(input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    # ...\n",
    "\n",
    "    def train(self, input_vectors, targets, iterations):\n",
    "        cumulative_errors = []\n",
    "        for current_iteration in range(iterations):\n",
    "            # Pick a data instance at random\n",
    "            random_data_index = np.random.randint(len(input_vectors))\n",
    "\n",
    "            input_vector = input_vectors[random_data_index]\n",
    "            target = targets[random_data_index]\n",
    "\n",
    "            # Compute the gradients and update the weights\n",
    "            derror_dbias, derror_dweights = self._compute_gradients(\n",
    "                input_vector, target\n",
    "            )\n",
    "\n",
    "            self._update_parameters(derror_dbias, derror_dweights)\n",
    "\n",
    "            # Measure the cumulative error for all the instances\n",
    "            if current_iteration % 100 == 0:\n",
    "                cumulative_error = 0\n",
    "                # Loop through all the instances to measure the error\n",
    "                for data_instance_index in range(len(input_vectors)):\n",
    "                    data_point = input_vectors[data_instance_index]\n",
    "                    target = targets[data_instance_index]\n",
    "\n",
    "                    prediction = self.predict(data_point)\n",
    "                    error = np.square(prediction - target)\n",
    "\n",
    "                    cumulative_error = cumulative_error + error\n",
    "                cumulative_errors.append(cumulative_error)\n",
    "\n",
    "        return cumulative_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a lot going on in the above code block, so here’s a line-by-line breakdown:\n",
    "\n",
    "* Line 8 picks a random instance from the dataset.\n",
    "\n",
    "* Lines 14 to 16 calculate the partial derivatives and return the derivatives for the bias and the weights. They use _compute_gradients(), which you defined earlier.\n",
    "\n",
    "* Line 18 updates the bias and the weights using _update_parameters(), which you defined in the previous code block.\n",
    "\n",
    "* Line 21 checks if the current iteration index is a multiple of 100. You do this to observe how the error changes every 100 iterations.\n",
    "\n",
    "* Line 24 starts the loop that goes through all the data instances.\n",
    "\n",
    "* Line 28 computes the prediction result.\n",
    "\n",
    "* Line 29 computes the error for every instance.\n",
    "\n",
    "* Line 31 is where you accumulate the sum of the errors using the cumulative_error variable. You do this because you want to plot a point with the error for all the data instances. Then, on line 32, you append the error to cumulative_errors, the array that stores the errors. You’ll use this array to plot the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_vectors = np.array(\n",
    "    [\n",
    "        [3, 1.5],\n",
    "        [2, 1],\n",
    "        [4, 1.5],\n",
    "        [3, 4],\n",
    "        [3.5, 0.5],\n",
    "        [2, 0.5],\n",
    "        [5.5, 1],\n",
    "        [1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "targets = np.array([0, 1, 0, 1, 0, 1, 1, 0])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "neural_network = NeuralNetwork(learning_rate)\n",
    "\n",
    "training_error = neural_network.train(input_vectors, targets, 10000)\n",
    "\n",
    "plt.plot(training_error)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Error for all training instances\")\n",
    "plt.savefig(\"cumulative_error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
