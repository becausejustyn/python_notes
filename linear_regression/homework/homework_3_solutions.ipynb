{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author: Chase Dowling (TA)\n",
    "contact: cdowling@uw.edu\n",
    "course: EE PMP 559, Spring '19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we'll construct the neccessary matrices for the above example network\n",
    "#node edge incidence matrix scaled by admittance\n",
    "#these are just arbitrary admittance values for this assignment\n",
    "F = np.array([[5.0,0.0,0.0,-5.0,0.0,0.0,0.0,0.0],\n",
    "              [0.0,3.0,0.0,0.0,-3.0,0.0,0.0,0.0],\n",
    "              [0.0,3.0,0.0,0.0,0.0,-3.0,0.0,0.0],\n",
    "              [0.0,0.0,13.0,-13.0,0.0,0.0,0.0,0.0],\n",
    "              [0.0,0.0,0.0,10.0,-10.0,0.0,0.0,0.0],\n",
    "              [0.0,0.0,0.0,0.0,5.0,-5.0,0.0,0.0],\n",
    "              [0.0,0.0,0.0,0.0,3.2,0.0,-3.2,0.0],\n",
    "              [0.0,0.0,0.0,0.0,2.5,0.0,0.0,-2.5]])\n",
    "\n",
    "self_admittance = np.sum(np.abs(F), axis=0)\n",
    "\n",
    "off_diag = np.array([[0, 0, 0, -5, 0, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, -3, -3, 0, 0],\n",
    "                     [0, 0, 0, -13, 0, 0, 0, 0],\n",
    "                     [-5, 0, -13, 0, -10, 0, 0, 0],\n",
    "                     [0, -3, 0, -10, 0, -5, -3.2, -2.5],\n",
    "                     [0, -3, 0, 0, -5, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, -3.2, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, -2.5, 0, 0, 0]])\n",
    "\n",
    "#admittance matrix\n",
    "B = np.diag(self_admittance) + off_diag\n",
    "\n",
    "#stacked\n",
    "H = np.vstack((F, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#true flows and power injections for reference\n",
    "\n",
    "f = 0.01*np.array([-1, -2, -1, 20, 17, 1, 10, 3])\n",
    "p = 0.01*np.array([-1, -3, 20, -2, 0, -1, -10, -3])\n",
    "\n",
    "z = np.expand_dims(np.append(f, p), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "#here are the samples, they are not formatted correctly, you'll need to format them correctly \n",
    "#in order to use linear_model.LinearRegression().fit()\n",
    "samples_1 = []\n",
    "\n",
    "for i in range(100):\n",
    "    samples_1.append(z + np.random.normal(0,0.02,size=z.shape)) #the true value + some noise\n",
    "    \n",
    "samples_1 = np.asarray(samples_1)[:,:,0]\n",
    "print(samples_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of solving for all x's at once: (100, 8) \n",
      "\n",
      "best x: [ 0.01433467 -0.00783658  0.03098395  0.01574861 -0.0013483  -0.00438868\n",
      " -0.03322899 -0.01426469] \n",
      "\n",
      "Error: 1.384233447099722 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LinearRegression().fit(H, samples_1.T) #find the best x for each sample\n",
    "x_s = model.coef_ #get the x's\n",
    "print(\"size of solving for all x's at once:\", x_s.shape, \"\\n\")  #100 x's of size 8\n",
    "x_hat = np.mean(x_s, axis=0)   #since the noise is Gaussian, the mean of all the best x's will minimize the loss for any z sample in sample_1 list\n",
    "print(\"best x:\", x_hat, \"\\n\")\n",
    "loss = np.linalg.norm(H.dot(x_hat) - z, 2)\n",
    "print(\"Error:\", loss, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_2 = []\n",
    "\n",
    "for i in range(100):\n",
    "    injection_noise = np.random.normal(0,0.01,size=z[0:8].shape)  #variance equal to 0.01\n",
    "    line_noise = np.random.normal(0,0.03,size=z[0:8].shape)       #variance equal to 0.03\n",
    "    samples_2.append(z + np.expand_dims(np.append(line_noise,injection_noise),axis=1)) #the true value + some noise\n",
    "    \n",
    "samples_2 = np.asarray(samples_2)[:,:,0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_one = np.ones(z.shape)[:,0]  #the weights object must be 1-dimensional\n",
    "model = linear_model.LinearRegression().fit(H, samples_2, sample_weight=weights_one)  \n",
    "x_hat_one = np.mean(model.coef_, axis=0)\n",
    "\n",
    "weights_f = 0.98*np.ones(f.shape)\n",
    "weights_p = 1.02*np.ones(p.shape)\n",
    "weights = np.concatenate((weights_f, weights_p))\n",
    "model = linear_model.LinearRegression().fit(H, samples_2, sample_weight=weights)  #this sets *all* samples to this weight scheme\n",
    "x_hat_bias = np.mean(model.coef_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.3807782306961334 \n",
      "\n",
      "Error: 1.3807781091262918 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = np.linalg.norm(H.dot(x_hat_one) - z, 2)\n",
    "print(\"Error:\", loss, \"\\n\")\n",
    "\n",
    "loss = np.linalg.norm(H.dot(x_hat_bias) - z, 2)\n",
    "print(\"Error:\", loss, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#16 x 100 array of z samples\n",
    "samples_3_array = np.loadtxt(\"homework_3_data.txt\")\n",
    "\n",
    "samples_3_array = samples_3_array.T               #data ended up getting saved transposed\n",
    "sample_3_mean = np.mean(samples_3_array, axis=0)  #compute the sample mean\n",
    "sample_3_var = np.var(samples_3_array, axis=0)    #compute the sample variance\n",
    "\n",
    "#apply a Chi-squared test statistic to each feature column of z\n",
    "test_stats = []\n",
    "for row in range(samples_3_array.shape[0]):\n",
    "    test_stat = np.sum(np.power(np.power(sample_3_var, -1)*(samples_3_array[row,:] - sample_3_mean),2))\n",
    "    test_stats.append(test_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier at index:  5\n",
      "outlier at index:  10\n",
      "outlier at index:  25\n",
      "outlier at index:  89\n",
      "\n",
      "\n",
      "size with outliers:  (96, 16)\n",
      "size without outliers:  (100, 16)\n"
     ]
    }
   ],
   "source": [
    "outliers = []\n",
    "\n",
    "for i in range(len(test_stats)):\n",
    "    if test_stats[i] > 100:  #inspect the test stat values and find that there are small values and 4 very large ones, this threshold is arbitrary\n",
    "        outliers.append(i)\n",
    "        print(\"outlier at index: \", i)\n",
    "        \n",
    "outliers = np.array(outliers) #conver to array object to use np delete function\n",
    "\n",
    "samples_3_clean = np.delete(samples_3_array, outliers, axis=0)\n",
    "print(\"\\n\")\n",
    "print(\"size with outliers: \", samples_3_clean.shape)\n",
    "print(\"size without outliers: \", samples_3_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss with outliers:  1.4200645723896477\n",
      "loss without outliers:  1.3856004602679295\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.LinearRegression().fit(H, samples_3_array.T)\n",
    "x_hat_outliers = np.mean(model.coef_, axis=0)\n",
    "loss_outliers = np.linalg.norm(H.dot(x_hat_outliers) - z, 2)\n",
    "\n",
    "model = linear_model.LinearRegression().fit(H, samples_3_clean.T)\n",
    "x_hat_clean = np.mean(model.coef_, axis=0)\n",
    "loss_clean = np.linalg.norm(H.dot(x_hat_clean) - z, 2)\n",
    "\n",
    "print(\"loss with outliers: \", loss_outliers)\n",
    "print(\"loss without outliers: \", loss_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
