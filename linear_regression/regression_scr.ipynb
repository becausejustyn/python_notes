{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha, beta, x_i):\n",
    "    return beta * x_i + alpha\n",
    "\n",
    "def error(alpha, beta, x_i, y_i):\n",
    "    \"\"\"the error from predicting beta * x_i + alpha when the actual value is y_i\"\"\"\n",
    "    return y_i - predict(alpha, beta, x_i)\n",
    "\n",
    "def sum_of_squared_errors(alpha, beta, x, y):\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y))\n",
    "\n",
    "def least_squares_fit(x,y):\n",
    "    \"\"\"given training values for x and y,\n",
    "    find the least-squares values of alpha and beta\"\"\"\n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(x_i, y_i, theta):\n",
    "    alpha, beta = theta\n",
    "    return error(alpha, beta, x_i, y_i) ** 2\n",
    "\n",
    "def squared_error_gradient(x_i, y_i, theta):\n",
    "    alpha, beta = theta\n",
    "    return [-2 * error(alpha, beta, x_i, y_i),       # alpha partial derivative\n",
    "            -2 * error(alpha, beta, x_i, y_i) * x_i] # beta partial derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose random value to start\n",
    "random.seed(0)\n",
    "theta = [random.random(), random.random()]\n",
    "alpha, beta = minimize_stochastic(\n",
    "    squared_error, \n",
    "    squared_error_gradient,\n",
    "    num_friends_good, \n",
    "    daily_minutes_good,\n",
    "    theta, \n",
    "    0.0001)\n",
    "\n",
    "print(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_friends_good = [49,41,40,25,21,21,19,19,18,18,16,15,15,15,15,14,14,13,13,13,13,12,12,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "print(\"alpha\", alpha)\n",
    "print(\"beta\", beta)\n",
    "\n",
    "print(\"r-squared\", r_squared(alpha, beta, num_friends_good, daily_minutes_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_beta(x, y):\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return(minimize_stochastic(\n",
    "        squared_error,\n",
    "        squared_error_gradient,\n",
    "        x, y,\n",
    "        beta_initial,\n",
    "        0.001)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "beta = estimate_beta(x, daily_minutes_good) # [30.63, 0.972, -1.868, 0.911]\n",
    "\n",
    "#This means our model looks like:\n",
    "#minutes = 30.63 + 0.972 friends âˆ’ 1.868 work hours + 0.911 phd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goodness of fit\n",
    "def multiple_r_squared(x, y, beta):\n",
    "    sum_of_squared_errors = sum(error(x_i, y_i, beta) ** 2\n",
    "                                for x_i, y_i in zip(x, y))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data):\n",
    "    \"\"\"randomly samples len(data) elements with replacement\"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data, stats_fn, num_samples):\n",
    "    \"\"\"evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n",
    "    return [stats_fn(bootstrap_sample(data))\n",
    "            for _ in range(num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 101 points all very close to 100\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# 101 points, 50 of them near 0, 50 of them near 200\n",
    "far_from_100 = ([99.5 + random.random()] + \n",
    "                [random.random() for _ in range(50)] + \n",
    "                [200 + random.random() for _ in range(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compute the median of each, both will be very close to 100. However, if you look at:  \n",
    "`bootstrap_statistic(close_to_100, median, 100)`  \n",
    "you will mostly see numbers really close to 100. Whereas if you look at:  \n",
    "`bootstrap_statistic(far_from_100, median, 100)`  \n",
    "you will see a lot of numbers close to 0 and a lot of numbers close to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sample_beta(sample):\n",
    "    x_sample, y_sample = list(zip(*sample)) # magic unzipping trick\n",
    "    return estimate_beta(x_sample, y_sample)\n",
    "\n",
    "random.seed(0) # so that you get the same results as me\n",
    "\n",
    "bootstrap_betas = bootstrap_statistic(zip(x, daily_minutes_good),\n",
    "                                          estimate_sample_beta, 100)\n",
    "\n",
    "#After which we can estimate the standard deviation of each coefficient:\n",
    "bootstrap_standard_errors = [\n",
    "    standard_deviation([beta[i] for beta in bootstrap_betas]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(beta_hat_j, sigma_hat_j):\n",
    "    if beta_hat_j > 0:\n",
    "        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n",
    "    else:\n",
    "        return 2 * normal_cdf(beta_hat_j / sigma_hat_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is a *hyperparameter* controlling how harsh the penalty is\n",
    "# sometimes it's called \"lambda\" but that already means something in Python\n",
    "\n",
    "def ridge_penalty(beta, alpha):\n",
    "  return alpha * dot(beta[1:], beta[1:])\n",
    "\n",
    "def squared_error_ridge(x_i, y_i, beta, alpha):\n",
    "    \"\"\"estimate error plus ridge penalty on beta\"\"\"\n",
    "    return error(x_i, y_i, beta) ** 2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "#which you can then plug into gradient descent in the usual way:\n",
    "\n",
    "def ridge_penalty_gradient(beta, alpha):\n",
    "    \"\"\"gradient of just the ridge penalty\"\"\"\n",
    "    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "def squared_error_ridge_gradient(x_i, y_i, beta, alpha):\n",
    "    \"\"\"the gradient corresponding to the ith squared error term\n",
    "    including the ridge penalty\"\"\"\n",
    "    return vector_add(squared_error_gradient(x_i, y_i, beta),\n",
    "                      ridge_penalty_gradient(beta, alpha))\n",
    "\n",
    "def estimate_beta_ridge(x, y, alpha):\n",
    "    \"\"\"use gradient descent to fit a ridge regression\n",
    "    with penalty alpha\"\"\"\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(partial(squared_error_ridge, alpha=alpha),\n",
    "                               partial(squared_error_ridge_gradient,\n",
    "                                       alpha=alpha),\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With alpha set to zero, thereâ€™s no penalty at all and we get the same results as before:\n",
    "\n",
    "random.seed(0)\n",
    "beta_0 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.0) # [30.6, 0.97, -1.87, 0.91]\n",
    "dot(beta_0[1:], beta_0[1:]) # 5.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_r_squared(x, daily_minutes_good, beta_0) # 0.680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we increase alpha, the goodness of fit gets worse, but the size of beta gets smaller:\n",
    "beta_0_01 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.01) # [30.6, 0.97, -1.86, 0.89]\n",
    "dot(beta_0_01[1:], beta_0_01[1:]) # 5.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_r_squared(x, daily_minutes_good, beta_0_01) # 0.680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0_1 = estimate_beta_ridge(x, daily_minutes_good, alpha=0.1) # [30.8, 0.95, -1.84, 0.54]\n",
    "dot(beta_0_1[1:], beta_0_1[1:]) # 4.60\n",
    "multiple_r_squared(x, daily_minutes_good, beta_0_1) # 0.680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = estimate_beta_ridge(x, daily_minutes_good, alpha=1) # [30.7, 0.90, -1.69, 0.085]\n",
    "dot(beta_1[1:], beta_1[1:]) # 3.69\n",
    "multiple_r_squared(x, daily_minutes_good, beta_1) # 0.676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_10 = estimate_beta_ridge(x, daily_minutes_good, alpha=10) # [28.3, 0.72, -0.91, -0.017]\n",
    "dot(beta_10[1:], beta_10[1:]) # 1.36 \n",
    "multiple_r_squared(x, daily_minutes_good, beta_10) # 0.573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_penalty(beta, alpha):\n",
    "    return(alpha * sum(abs(beta_i) for beta_i in beta[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
